{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DDuP5tR3esNFUJ9B2MVhBWxIDkZCRun2",
      "authorship_tag": "ABX9TyM3OCvUCCA7milV2ggXGDKY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "31wG5AoixGfv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import glob\n",
        "import cv2  # ----- OpenCV 라이브러리\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torchvision  # ----- 컴퓨터 비전 (computer vision) 용도의 패키지\n",
        "import torchvision.transforms as transforms  # ----- 데이터 전처리를 위해 사용되는 패키지\n",
        "import torchvision.models as models  # ----- 다양한 파이토치 네트워크를 사용할 수 있도록 도와주는 패키지\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/FLY_AI/KMK/data/catanddog/train'  # ----- 이미지 데이터가 위치한 경로 지정\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize([256, 256]),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "    data_path,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=8,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AONVIQXp3Zlf",
        "outputId": "fa8d2879-63cb-4c1e-8ed9-52ac5645674e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy0JB44631-i",
        "outputId": "995c4a68-2c50-43ad-bcc1-d706a40b8fbf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 97.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "resnet18 = models.resnet18()\n",
        "alexnet = models.alexnet()\n",
        "vgg16 = models.vgg16()\n",
        "squeezenet = models.squeezenet1_0()\n",
        "densenet = models.densenet161()\n",
        "inception = models.inception_v3()\n",
        "googlenet = models.googlenet()\n",
        "shufflenet = models.shufflenet_v2_x1_0()\n",
        "mobilenet_v2 = models.mobilenet_v2()\n",
        "mobilenet_v3_large= models.mobilenet_v3_large()\n",
        "mobilenet_v3_small= models.mobilenet_v3_small()\n",
        "resnext50_32x4d= models.resnext50_32x4d()\n",
        "wide_resnet50_2= models.wide_resnet50_2()\n",
        "mnasnet = models.mnasnet1_0()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYk6zgpK461M",
        "outputId": "d2f12b68-b183-4e87-f4be-269be3dab1e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "set_parameter_requires_grad(resnet18, True)"
      ],
      "metadata": {
        "id": "LW9LbtOZ5b3M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18.fc = nn.Linear(512, 2)"
      ],
      "metadata": {
        "id": "E4KB8sSJ5lyz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in resnet18.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "      print(name, param.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpImKVGZ5pqR",
        "outputId": "fb2999b0-fbd9-413c-f8f8-3dca2510ec5e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc.weight True\n",
            "fc.bias True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = torch.nn.Linear(512, 2)\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer = torch.optim.Adam(model.fc.parameters())\n",
        "cost = torch.nn.CrossEntropyLoss()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftVZYeYG5tpu",
        "outputId": "1129ed68-5fdd-43f9-b1fb-b5f64c23adc8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_model(model, dataloaders, criterion, optimizer, devicem, num_epochs=13,\n",
        "#                 is_train=True):\n",
        "#     since = time.time()\n",
        "#     acc_history = []\n",
        "#     loss_history = []\n",
        "#     best_acc = 0.0\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "#         print('-' * 10)\n",
        "\n",
        "#         running_loss = 0.0\n",
        "#         running_corrects = 0.0\n",
        "\n",
        "#         for inputs, labels in dataloaders:\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             model.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(inputs) # Propagation\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             running_loss += loss.item() * inputs.size(0)\n",
        "#             running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "#         epoch_loss = running_loss / len(dataloaders.dataset)\n",
        "#         epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
        "#         print(f\"Loss: {epoch_loss} Acc: {epoch_acc}\")\n",
        "\n",
        "#         if epoch_acc > best_acc:\n",
        "#             best_acc = epoch_acc\n",
        "\n",
        "#         acc_history.append(epoch_acc.item())\n",
        "\n",
        "#         loss_history.append(epoch_loss)\n",
        "#         torch.save(model.state_dict(), os.path.join('/content/drive/MyDrive/FLY_AI/KMK/data/catanddog/', '{0:0=2d}.pth'.format(epoch)))\n",
        "#         print()\n",
        "\n",
        "#     time_elapsed = time.time() - since\n",
        "#     print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
        "#     return model, acc_history, loss_history"
      ],
      "metadata": {
        "id": "tkko1GXi6Cs7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=13, is_train=True):\n",
        "    since = time.time()\n",
        "    acc_history = []\n",
        "    loss_history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    save_dir = '/content/drive/MyDrive/FLY_AI/KMK/data/catanddog/'\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        if is_train:\n",
        "            model.train()  # 학습 모드\n",
        "        else:\n",
        "            model.eval()  # 평가 모드\n",
        "\n",
        "        for inputs, labels in dataloaders:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            model.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)  # Propagation\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
        "        epoch_acc = running_corrects / len(dataloaders.dataset)\n",
        "        print(f\"Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "\n",
        "        acc_history.append(epoch_acc)\n",
        "        loss_history.append(epoch_loss)\n",
        "\n",
        "        # Save model checkpoint\n",
        "        torch.save(model.state_dict(), os.path.join(save_dir, '{0:0=2d}.pth'.format(epoch)))\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    return model, acc_history, loss_history"
      ],
      "metadata": {
        "id": "SF5LeD-O8VNx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print('\\t', name)\n",
        "\n",
        "optimizer = optim.Adam(params_to_update)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7goFSSw7uwY",
        "outputId": "6860785a-6279-479c-fe32-6d3d2302324d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_acc_hist, train_loss_hist = train_model(model, train_loader, criterion, optimizer, device, num_epochs=13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lReWkQya74Kf",
        "outputId": "3318a36e-4a07-4760-c387-e9c2cfbe40fa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/12\n",
            "----------\n",
            "Loss: 0.2440 Acc: 0.9115\n",
            "\n",
            "Epoch 1/12\n",
            "----------\n",
            "Loss: 0.2721 Acc: 0.9479\n",
            "\n",
            "Epoch 2/12\n",
            "----------\n",
            "Loss: 0.2239 Acc: 0.9479\n",
            "\n",
            "Epoch 3/12\n",
            "----------\n",
            "Loss: 0.1700 Acc: 0.9479\n",
            "\n",
            "Epoch 4/12\n",
            "----------\n",
            "Loss: 0.1537 Acc: 0.9531\n",
            "\n",
            "Epoch 5/12\n",
            "----------\n",
            "Loss: 0.1428 Acc: 0.9479\n",
            "\n",
            "Epoch 6/12\n",
            "----------\n",
            "Loss: 0.1312 Acc: 0.9479\n",
            "\n",
            "Epoch 7/12\n",
            "----------\n",
            "Loss: 0.1199 Acc: 0.9479\n",
            "\n",
            "Epoch 8/12\n",
            "----------\n",
            "Loss: 0.1193 Acc: 0.9479\n",
            "\n",
            "Epoch 9/12\n",
            "----------\n",
            "Loss: 0.1241 Acc: 0.9531\n",
            "\n",
            "Epoch 10/12\n",
            "----------\n",
            "Loss: 0.1037 Acc: 0.9635\n",
            "\n",
            "Epoch 11/12\n",
            "----------\n",
            "Loss: 0.1228 Acc: 0.9531\n",
            "\n",
            "Epoch 12/12\n",
            "----------\n",
            "Loss: 0.0862 Acc: 0.9583\n",
            "\n",
            "Training complete in 6m 41s\n",
            "Best val Acc: 0.963542\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f942b1f062de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_acc_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/drive/MyDrive/FLY_AI/KMK/data/catanddog/test'\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "    transforms.Resize([224]),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "test_dataset = torchvision.datasets.ImageFolder(\n",
        "    test_path,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H31u6-dc8AxL",
        "outputId": "8757021b-2e57-4c42-a795-a92bbbeedb6f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, dataloaders, device):\n",
        "    since = time.time()\n",
        "    acc_history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    saved_models = glob.glob('/content/drive/MyDrive/FLY_AI/KMK/data/catanddog/*.pth')\n",
        "    saved_models.sort()\n",
        "    print('saved_model', saved_models)\n",
        "\n",
        "    for model_path in saved_models:\n",
        "        print(\"Loading model\", model_path)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "        model.to(device)\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "\n",
        "\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            preds[preds >= 0.5] = 1\n",
        "            preds[preds < 0.5] = 0\n",
        "            running_corrects += preds.eq(labels.cpu()).int.sum()\n",
        "\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
        "        print(f\"Acc: {epoch_acc}\")"
      ],
      "metadata": {
        "id": "Tkl_aPnz8_Yo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}