{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a1DR5X85xrva",
        "outputId": "fc8c64d4-b1bb-4f10-ca8f-096a388e9018",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "\u001b[33mWARNING: gymnasium 1.0.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Collecting ale-py>=0.9 (from gymnasium[accept-rom-license,atari])\n",
            "  Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ale-py\n",
            "Successfully installed ale-py-0.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[atari,accept-rom-license]\n",
        "# !pip install gymnasium[pong,accept-rom-license]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import ale_py\n",
        "\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "env = gym.make(\"ALE/Pong-v5\", render_mode='rgb_array') # 환경 만들기"
      ],
      "metadata": {
        "id": "pV0fajGOxxZv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "71h6I7DeCtJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obs, info = env.reset()"
      ],
      "metadata": {
        "id": "2_LVvDraCQ6O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs, r, done, _, info = env.step(1)"
      ],
      "metadata": {
        "id": "D25Ny0FyCf62"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "A_vwWZJMCkxd",
        "outputId": "cefd1180-fc32-4753-c2d7-1b025cf68612"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17]],\n",
              "\n",
              "       [[144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        ...,\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17]],\n",
              "\n",
              "       [[144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        ...,\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        ...,\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236]],\n",
              "\n",
              "       [[236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        ...,\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236]],\n",
              "\n",
              "       [[236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        ...,\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-49846f44-5b0c-43d0-94d1-bbcf2e2cdcab\" class=\"ndarray_repr\"><pre>ndarray (210, 160, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAACb0lEQVR4nO3aMWrCYBiA4aZ4Ae/i0u4Fwdt4EPEynbq3i0fJIbqVLKKFJsG3zzMJJvrBy8cP0eHpivN+e+0tHsiwZMi315eb13x8fi0wyTIux8PNa3an91lneJ7101mdwHECx23W+uLpWXvP2fzopmftPWfzX7HBcQLHCRwncJzAcQLHCRwncJzAcQLHCRy32rPo//D8eWrJ589TNjhO4DiB4xb9TxbLs8FxAscN4ziuPQMzssFxAscJHCdwnMBxAscJHCdwnMBxfmyIs8FxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxm7UH4LbL8fDzend6/9W9NjhO4DiB4wSOEzhO4DiB4wSOEzhO4DiB4wSOEzhO4DiB44bzfrv2DMzIBscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscN4ziuPQMzssFxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHPcNFlUc+oUlo5YAAAAASUVORK5CYII=\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17]],\n",
              "\n",
              "       [[144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        ...,\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17]],\n",
              "\n",
              "       [[144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        ...,\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17],\n",
              "        [144,  72,  17]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        ...,\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236]],\n",
              "\n",
              "       [[236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        ...,\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236]],\n",
              "\n",
              "       [[236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        ...,\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236],\n",
              "        [236, 236, 236]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-49846f44-5b0c-43d0-94d1-bbcf2e2cdcab button').onclick = (e) => {\n",
              "        document.querySelector('#id-49846f44-5b0c-43d0-94d1-bbcf2e2cdcab').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-49846f44-5b0c-43d0-94d1-bbcf2e2cdcab button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "hN9DeCERCuPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 본 코드"
      ],
      "metadata": {
        "id": "H9ZEOPWUCwbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Configuration paramaters for the whole setup\n",
        "seed = 42\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "epsilon = 1.0  # Epsilon greedy parameter\n",
        "epsilon_min = 0.1  # Minimum epsilon greedy parameter\n",
        "epsilon_max = 1.0  # Maximum epsilon greedy parameter\n",
        "epsilon_interval = (\n",
        "    epsilon_max - epsilon_min\n",
        ")  # Rate at which to reduce chance of random action being taken\n",
        "batch_size = 64  # Size of batch taken from replay buffer\n",
        "max_steps_per_episode = 1000"
      ],
      "metadata": {
        "id": "WZ5JPdNSzupR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_actions = env.action_space.n\n",
        "\n",
        "class QModel(nn.Module):\n",
        "    def __init__(self, num_actions):\n",
        "        super(QModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(3136, 512)\n",
        "        self.fc2 = nn.Linear(512, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = nn.functional.relu(self.conv3(x))\n",
        "        x = self.flatten(x)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        action = self.fc2(x)\n",
        "        return action"
      ],
      "metadata": {
        "id": "dc4_u5zq0gWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e5bbdc-40fc-453d-efa0-c1ad4a016546"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The first model makes the predictions for Q-values which are used to\n",
        "# make a action.\n",
        "model = QModel(num_actions)\n",
        "model.to('cuda')\n",
        "\n",
        "# Build a target model for the prediction of future rewards.\n",
        "# The weights of a target model get updated every 10000 steps thus when the\n",
        "# loss between the Q-values is calculated the target Q-value is stable.\n",
        "model_target = QModel(num_actions)\n",
        "model_target.to('cuda')\n",
        "\n",
        "loss_function = nn.SmoothL1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00025)"
      ],
      "metadata": {
        "id": "3u3lUayG0o7T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experience replay buffers\n",
        "action_history = []\n",
        "state_history = []\n",
        "state_next_history = []\n",
        "rewards_history = []\n",
        "done_history = []\n",
        "episode_reward_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0\n",
        "frame_count = 0\n",
        "\n",
        "# Number of frames to take random action and observe output\n",
        "epsilon_random_frames = 50000\n",
        "# Number of frames for exploration\n",
        "epsilon_greedy_frames = 100000.0\n",
        "# Maximum replay length\n",
        "# Note: The Deepmind paper suggests 1000000 however this causes memory issues\n",
        "max_memory_length = 500000\n",
        "# Train the model after 4 actions\n",
        "update_after_actions = 4\n",
        "# How often to update the target network\n",
        "update_target_network = 10000"
      ],
      "metadata": {
        "id": "3hGodqNc08rZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Grayscale(),\n",
        "    T.Resize((84, 84)),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Function to preprocess the state\n",
        "def preprocess_state(state):\n",
        "    state = preprocess(state).unsqueeze(0)\n",
        "    return state"
      ],
      "metadata": {
        "id": "-kZIWhM71Ns-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**이미지 포맷:**\n",
        "1. (N)CHW\n",
        "2. (N)HWC\n",
        "  - 주로 이거 !"
      ],
      "metadata": {
        "id": "BkUDaZTiBXDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to select an action\n",
        "def get_greedy_epsilon(model, state):\n",
        "    global epsilon\n",
        "\n",
        "    #if frame_count < epsilon_random_frames or np.random.rand(1)[0] < epsilon:\n",
        "    if np.random.rand(1)[0] < epsilon:\n",
        "        action = np.random.randint(num_actions)\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            # add a batch axis\n",
        "            #state = state.unsqueeze(0)\n",
        "            # compute the q-values\n",
        "            q_values = model(state)\n",
        "            # the action of maximum q-value\n",
        "            action = q_values.argmax().item()\n",
        "\n",
        "    # decay epsilon\n",
        "    epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "    epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "CPfiO0nZ09Yi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_greedy_action(model, state):\n",
        "    global epsilon\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #state = state.unsqueeze(0) # batch dimension\n",
        "        q_values = model(state)\n",
        "        action = q_values.argmax().item()\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "FVhhXbi92f3t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample a batch of _batch_size from replay buffers\n",
        "# return numpy.ndarrays\n",
        "def sample_batch(_batch_size):\n",
        "    # Get indices of samples for replay buffers\n",
        "    indices = np.random.choice(range(len(done_history)), size=_batch_size, replace=False)\n",
        "\n",
        "    state_sample = np.array([state_history[i].squeeze(0).numpy() for i in indices])\n",
        "    state_next_sample = np.array([state_next_history[i].squeeze(0).numpy() for i in indices])\n",
        "    rewards_sample = np.array([rewards_history[i] for i in indices], dtype=np.float32)\n",
        "    action_sample = np.array([action_history[i] for i in indices])\n",
        "    done_sample = np.array([float(done_history[i]) for i in indices])\n",
        "\n",
        "    return state_sample, state_next_sample, rewards_sample, action_sample, done_sample"
      ],
      "metadata": {
        "id": "3_9hivE42mlp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to update the Q-network\n",
        "def update_network():\n",
        "    # sample a batch of ...\n",
        "    state_sample, state_next_sample, rewards_sample, action_sample, done_sample = \\\n",
        "        sample_batch(batch_size)\n",
        "\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    state_sample = torch.tensor(state_sample, dtype=torch.float32).to('cuda')\n",
        "    state_next_sample = torch.tensor(state_next_sample, dtype=torch.float32).to('cuda')\n",
        "    action_sample = torch.tensor(action_sample, dtype=torch.int64).to('cuda')\n",
        "    rewards_sample = torch.tensor(rewards_sample, dtype=torch.float32).to('cuda')\n",
        "    done_sample = torch.tensor(done_sample, dtype=torch.float32).to('cuda')\n",
        "\n",
        "    # Compute the target Q-values for the states\n",
        "    with torch.no_grad():\n",
        "        future_rewards = model_target(state_next_sample)\n",
        "\n",
        "        # compute the q-value for the next state and the action maximizing the q-value\n",
        "        max_q_values = future_rewards.max(dim=1).values\n",
        "\n",
        "        # compute the target q-value\n",
        "        # if the step was final, max_q_values should not be added\n",
        "        target_q_values = rewards_sample + gamma * max_q_values * (1. - done_sample)\n",
        "\n",
        "    # It's forward propagation! Compute the Q-values for the taken actions\n",
        "    q_values = model(state_sample)\n",
        "    q_values_action = q_values.gather(dim=1, index=action_sample.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = loss_function(q_values_action, target_q_values)\n",
        "\n",
        "    # Perform the optimization step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "067LMCDM2xDq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:  # Run until solved\n",
        "    state, info = env.reset()\n",
        "    state, reward, done, _, info = env.step(1)\n",
        "    state = preprocess_state(state)\n",
        "    episode_reward = 0\n",
        "\n",
        "    for timestep in range(1, max_steps_per_episode):\n",
        "        frame_count += 1\n",
        "\n",
        "        # Select an action\n",
        "        action = get_greedy_epsilon(model, state.to('cuda'))\n",
        "\n",
        "        # Take the selected action\n",
        "        state_next, reward, done, _, info = env.step(action)\n",
        "        state_next = preprocess_state(state_next)\n",
        "\n",
        "        episode_reward += reward\n",
        "\n",
        "        # Store the transition in the replay buffer\n",
        "        action_history.append(action)\n",
        "        state_history.append(state)\n",
        "        state_next_history.append(state_next)\n",
        "        rewards_history.append(reward)\n",
        "        done_history.append(done)\n",
        "\n",
        "        state = state_next\n",
        "\n",
        "        # Update every fourth frame and once batch size is over 32\n",
        "        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
        "            update_network()\n",
        "\n",
        "        if frame_count % update_target_network == 0:\n",
        "            model_target.load_state_dict(model.state_dict())\n",
        "\n",
        "        # Limit the state and reward history\n",
        "        if len(rewards_history) > max_memory_length:\n",
        "            del rewards_history[:1]\n",
        "            del state_history[:1]\n",
        "            del state_next_history[:1]\n",
        "            del action_history[:1]\n",
        "            del done_history[:1]\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    episode_count += 1\n",
        "    episode_reward_history.append(episode_reward)\n",
        "\n",
        "    # Update running reward to check condition for solving\n",
        "    if len(episode_reward_history) > 100:\n",
        "        del episode_reward_history[:1]\n",
        "    running_reward = np.mean(episode_reward_history)\n",
        "\n",
        "    if episode_count % 10 == 0:\n",
        "        print(f\"Episode: {episode_count}, Frame count: {frame_count}, Running reward: {running_reward}\")\n",
        "\n",
        "    if episode_count % 5000 == 0:\n",
        "        torch.save(model, 'model.{}'.format(episode_count))\n",
        "    if running_reward > 20:\n",
        "        print(f\"Solved at episode {episode_count}!\")\n",
        "        break\n",
        "    if episode_count >= 100:\n",
        "        break\n",
        "\n",
        "\n",
        "torch.save(model, 'model.final')"
      ],
      "metadata": {
        "id": "pgPMTl6F2_st",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f58d49-6d56-4b91-95b1-40101bb91495"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 10, Frame count: 9229, Running reward: -20.2\n",
            "Episode: 20, Frame count: 18214, Running reward: -20.25\n",
            "Episode: 30, Frame count: 26436, Running reward: -20.3\n",
            "Episode: 40, Frame count: 35325, Running reward: -20.05\n",
            "Episode: 50, Frame count: 43595, Running reward: -20.18\n",
            "Episode: 60, Frame count: 52245, Running reward: -20.15\n",
            "Episode: 70, Frame count: 60333, Running reward: -20.257142857142856\n",
            "Episode: 80, Frame count: 68607, Running reward: -20.3375\n",
            "Episode: 90, Frame count: 76817, Running reward: -20.377777777777776\n",
            "Episode: 100, Frame count: 85496, Running reward: -20.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, sys\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import imageio\n",
        "\n",
        "anim_file = 'pong.gif'\n",
        "\n",
        "turn =  0\n",
        "board, info = env.reset()\n",
        "state = preprocess_state(board)\n",
        "board, reward, done, _, info = env.step(1)\n",
        "state = preprocess_state(board)\n",
        "plt.imshow(board)\n",
        "plt.savefig('image_at_turn_{:04d}.png'.format(turn))\n",
        "\n",
        "for timestep in range(1, 100):\n",
        "    turn += 1\n",
        "    action = get_greedy_action(model, state.to('cuda'))\n",
        "    #print(action)\n",
        "    board, reward, done, _, info = env.step(action)\n",
        "    state = preprocess_state(board)\n",
        "    plt.imshow(board)\n",
        "    plt.savefig('image_at_turn_{:04d}.png'.format(turn))\n",
        "\n",
        "    if done:\n",
        "        break"
      ],
      "metadata": {
        "id": "s4lM71lH5FFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "7505aeb5-28a8-409d-9764-fc4ab30f9c71"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate animated gif file\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "    filenames = glob.glob('image_at_turn_*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n"
      ],
      "metadata": {
        "id": "E4Wm0t1m5fa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67efd249-dd1a-4432-8ae4-f88496cb42c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-512146e1f840>:6: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl2oc7BnD9Kl",
        "outputId": "ed5e5799-d437-4333-cfa9-f44d4cd97a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0D7apgpD7_h",
        "outputId": "e7864fb7-6d2c-4525-99fd-6b09d69be137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/FLY_AI/RL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdSu8EfhEQtH",
        "outputId": "49ac7173-4fde-4560-c085-105f05ab6cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'P1. atari-breakout-cuda.ipynb'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp atari.gif drive/MyDrive/FLY_AI/RL/atari.gif #"
      ],
      "metadata": {
        "id": "LajeHU9JEk17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8a1mKkFFEir"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}