{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a1DR5X85xrva",
        "outputId": "348ab54c-dad5-43dd-986c-9fff802ced42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium[accept-rom-license,atari]\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "\u001b[33mWARNING: gymnasium 1.0.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium[accept-rom-license,atari])\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting ale-py>=0.9 (from gymnasium[accept-rom-license,atari])\n",
            "  Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: farama-notifications, gymnasium, ale-py\n",
            "Successfully installed ale-py-0.10.1 farama-notifications-0.0.4 gymnasium-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[atari,accept-rom-license]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import ale_py\n",
        "\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "env = gym.make(\"BreakoutNoFrameskip-v4\", render_mode='rgb_array') # 환경 만들기"
      ],
      "metadata": {
        "id": "pV0fajGOxxZv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "71h6I7DeCtJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obs, info = env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "2_LVvDraCQ6O",
        "outputId": "094b7552-55aa-4775-d95f-ca171d7aff71"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-8bbd405b-5f45-4b56-9005-8edbdaeade58\" class=\"ndarray_repr\"><pre>ndarray (210, 160, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAACu0lEQVR4nO3dsW0TYRiA4QS5RkxARcEIEQNYLpjGEzCBx0AMQGGloEQZBlEgRJEiygL+IZZ9d/bL85Sn090vvfl8v+SzcnMDAMDZ3c55s91u989zttvtbOcfa+rrj+51yjVfnWMxXK7VUjeec1Jfcv6xzjWpUzPBcYtN8LUbfSpc2mSb4DgTfITRdE7xjD8XExy32AQf+1c/9flLXXNqJhjgYt1e43OFl/MMjhM4TuA4geMEjhM4TuA4geMEjhM4TuA4geMEjhM4bvjKzqW9/snfjb72NcFxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdw3PDF94fNZs51cKLvg+MmOE7gOIHjBI4TOG64i35692vOdTARExwncJzAcQLHCRw33EX/fP1nznUwERMcJ3CcwHECxwkcN95Fv3+ccx2c6sfhwyY4TuA4geMEjhM4briL/vz0ds51cKL14LgJjhM4TuA4geMEjhvuoh+/fJpxGZxsffj3hSY4TuA4geMEjhM4briL/ra/m3MdnOjj2j+n/C8JHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdw3Orrm99Lr+E6PGw2R51/t99PtJKDPtzfHzxuguMEjhM4brX0Aq7GzM/UczHBcSY44ko/YAAAAAAAAFjUMyEkRxlHStXAAAAAAElFTkSuQmCC\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-8bbd405b-5f45-4b56-9005-8edbdaeade58 button').onclick = (e) => {\n",
              "        document.querySelector('#id-8bbd405b-5f45-4b56-9005-8edbdaeade58').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-8bbd405b-5f45-4b56-9005-8edbdaeade58 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs, r, done, _, info = env.step(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D25Ny0FyCf62",
        "outputId": "d47a5fba-f65f-4e29-d4da-43cd46b9f7af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "A_vwWZJMCkxd",
        "outputId": "b3c76f2c-1ffa-4358-fe1d-18176be73d90"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-8e80263b-26db-4957-b443-3b13e0b140ef\" class=\"ndarray_repr\"><pre>ndarray (210, 160, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAACyElEQVR4nO3dMW7TYBiA4RZ1RpyAiYEjVBwgysBpegJOkGMgDsAQdWBEPQxiQIihQ8UF+kMjx3by5nlGy7J/6e0XW2qi/+oKAICju17yZrvd7r/n3N3dLXb+oea+/uheU6756hiL4XTdrHXjJSf1Jecf6liTOjcTHLfaBJ+70afCqU22CY4zwQcYTeccz/hjMcFxq03woX/1c5+/1jXnZoIBTtb1OT5XeDnP4DiB4wSOEzhO4DiB4wSOEzhO4DiB4wSOEzhO4DiB44Zf2Tm1r3/yb6N/+5rgOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOG74xfeH7XbJdTDR98FxExwncJzAcQLHCRw3fIt+evdryXUwExMcJ3CcwHECxwkcN3yL/vn6z5LrYCYmOE7gOIHjBI4TOG78Fv3+ccl1MNWP5w+b4DiB4wSOEzhO4LjhW/Tnp7dLroOJNoPjJjhO4DiB4wSOEzhu+Bb9+OXTgstgss3zvy80wXECxwkcJ3CcwHHDt+hv+9sl18FEHzc2p7xIAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdw3AUFfthuL3DX6wsKfJkEjhM4bvgD8J7b/X7tJazABMcJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHHfz9c3vtddwHg7dHn7h3Ww/3N8/e9wExwkcJ3DcBW3xPtGZ7hBvguNMcMSZfsAAAAAAAACwqr9E9UtzYdmUKAAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-8e80263b-26db-4957-b443-3b13e0b140ef button').onclick = (e) => {\n",
              "        document.querySelector('#id-8e80263b-26db-4957-b443-3b13e0b140ef').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-8e80263b-26db-4957-b443-3b13e0b140ef button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "hN9DeCERCuPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 본 코드"
      ],
      "metadata": {
        "id": "H9ZEOPWUCwbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Configuration paramaters for the whole setup\n",
        "seed = 42\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "epsilon = 1.0  # Epsilon greedy parameter\n",
        "epsilon_min = 0.1  # Minimum epsilon greedy parameter\n",
        "epsilon_max = 1.0  # Maximum epsilon greedy parameter\n",
        "epsilon_interval = (\n",
        "    epsilon_max - epsilon_min\n",
        ")  # Rate at which to reduce chance of random action being taken\n",
        "batch_size = 64  # Size of batch taken from replay buffer\n",
        "max_steps_per_episode = 1000"
      ],
      "metadata": {
        "id": "WZ5JPdNSzupR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_actions = env.action_space.n\n",
        "\n",
        "class QModel(nn.Module):\n",
        "    def __init__(self, num_actions):\n",
        "        super(QModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(3136, 512)\n",
        "        self.fc2 = nn.Linear(512, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = nn.functional.relu(self.conv3(x))\n",
        "        x = self.flatten(x)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        action = self.fc2(x)\n",
        "        return action"
      ],
      "metadata": {
        "id": "dc4_u5zq0gWg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The first model makes the predictions for Q-values which are used to\n",
        "# make a action.\n",
        "model = QModel(num_actions)\n",
        "model.to('cuda')\n",
        "\n",
        "# Build a target model for the prediction of future rewards.\n",
        "# The weights of a target model get updated every 10000 steps thus when the\n",
        "# loss between the Q-values is calculated the target Q-value is stable.\n",
        "model_target = QModel(num_actions)\n",
        "model_target.to('cuda')\n",
        "\n",
        "loss_function = nn.SmoothL1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00025)"
      ],
      "metadata": {
        "id": "3u3lUayG0o7T"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experience replay buffers\n",
        "action_history = []\n",
        "state_history = []\n",
        "state_next_history = []\n",
        "rewards_history = []\n",
        "done_history = []\n",
        "episode_reward_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0\n",
        "frame_count = 0\n",
        "\n",
        "# Number of frames to take random action and observe output\n",
        "epsilon_random_frames = 50000\n",
        "# Number of frames for exploration\n",
        "epsilon_greedy_frames = 100000.0\n",
        "# Maximum replay length\n",
        "# Note: The Deepmind paper suggests 1000000 however this causes memory issues\n",
        "max_memory_length = 500000\n",
        "# Train the model after 4 actions\n",
        "update_after_actions = 4\n",
        "# How often to update the target network\n",
        "update_target_network = 10000"
      ],
      "metadata": {
        "id": "3hGodqNc08rZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Grayscale(),\n",
        "    T.Resize((84, 84)),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Function to preprocess the state\n",
        "def preprocess_state(state):\n",
        "    state = preprocess(state).unsqueeze(0)\n",
        "    return state"
      ],
      "metadata": {
        "id": "-kZIWhM71Ns-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**이미지 포맷:**\n",
        "1. (N)CHW\n",
        "2. (N)HWC\n",
        "  - 주로 이거 !"
      ],
      "metadata": {
        "id": "BkUDaZTiBXDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to select an action\n",
        "def get_greedy_epsilon(model, state):\n",
        "    global epsilon\n",
        "\n",
        "    #if frame_count < epsilon_random_frames or np.random.rand(1)[0] < epsilon:\n",
        "    if np.random.rand(1)[0] < epsilon:\n",
        "        action = np.random.randint(num_actions)\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            # add a batch axis\n",
        "            #state = state.unsqueeze(0)\n",
        "            # compute the q-values\n",
        "            q_values = model(state)\n",
        "            # the action of maximum q-value\n",
        "            action = q_values.argmax().item()\n",
        "\n",
        "    # decay epsilon\n",
        "    epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "    epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "CPfiO0nZ09Yi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_greedy_action(model, state):\n",
        "    global epsilon\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #state = state.unsqueeze(0) # batch dimension\n",
        "        q_values = model(state)\n",
        "        action = q_values.argmax().item()\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "FVhhXbi92f3t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample a batch of _batch_size from replay buffers\n",
        "# return numpy.ndarrays\n",
        "def sample_batch(_batch_size):\n",
        "    # Get indices of samples for replay buffers\n",
        "    indices = np.random.choice(range(len(done_history)), size=_batch_size, replace=False)\n",
        "\n",
        "    state_sample = np.array([state_history[i].squeeze(0).numpy() for i in indices])\n",
        "    state_next_sample = np.array([state_next_history[i].squeeze(0).numpy() for i in indices])\n",
        "    rewards_sample = np.array([rewards_history[i] for i in indices], dtype=np.float32)\n",
        "    action_sample = np.array([action_history[i] for i in indices])\n",
        "    done_sample = np.array([float(done_history[i]) for i in indices])\n",
        "\n",
        "    return state_sample, state_next_sample, rewards_sample, action_sample, done_sample"
      ],
      "metadata": {
        "id": "3_9hivE42mlp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to update the Q-network\n",
        "def update_network():\n",
        "    # sample a batch of ...\n",
        "    state_sample, state_next_sample, rewards_sample, action_sample, done_sample = \\\n",
        "        sample_batch(batch_size)\n",
        "\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    state_sample = torch.tensor(state_sample, dtype=torch.float32).to('cuda')\n",
        "    state_next_sample = torch.tensor(state_next_sample, dtype=torch.float32).to('cuda')\n",
        "    action_sample = torch.tensor(action_sample, dtype=torch.int64).to('cuda')\n",
        "    rewards_sample = torch.tensor(rewards_sample, dtype=torch.float32).to('cuda')\n",
        "    done_sample = torch.tensor(done_sample, dtype=torch.float32).to('cuda')\n",
        "\n",
        "    # Compute the target Q-values for the states\n",
        "    with torch.no_grad():\n",
        "        future_rewards = model_target(state_next_sample)\n",
        "\n",
        "        # compute the q-value for the next state and the action maximizing the q-value\n",
        "        max_q_values = future_rewards.max(dim=1).values\n",
        "\n",
        "        # compute the target q-value\n",
        "        # if the step was final, max_q_values should not be added\n",
        "        target_q_values = rewards_sample + gamma * max_q_values * (1. - done_sample)\n",
        "\n",
        "    # It's forward propagation! Compute the Q-values for the taken actions\n",
        "    q_values = model(state_sample)\n",
        "    q_values_action = q_values.gather(dim=1, index=action_sample.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = loss_function(q_values_action, target_q_values)\n",
        "\n",
        "    # Perform the optimization step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "067LMCDM2xDq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:  # Run until solved\n",
        "    state, info = env.reset()\n",
        "    state, reward, done, _, info = env.step(1)\n",
        "    state = preprocess_state(state)\n",
        "    episode_reward = 0\n",
        "\n",
        "    for timestep in range(1, max_steps_per_episode):\n",
        "        frame_count += 1\n",
        "\n",
        "        # Select an action\n",
        "        action = get_greedy_epsilon(model, state.to('cuda'))\n",
        "\n",
        "        # Take the selected action\n",
        "        state_next, reward, done, _, info = env.step(action)\n",
        "        state_next = preprocess_state(state_next)\n",
        "\n",
        "        episode_reward += reward\n",
        "\n",
        "        # Store the transition in the replay buffer\n",
        "        action_history.append(action)\n",
        "        state_history.append(state)\n",
        "        state_next_history.append(state_next)\n",
        "        rewards_history.append(reward)\n",
        "        done_history.append(done)\n",
        "\n",
        "        state = state_next\n",
        "\n",
        "        # Update every fourth frame and once batch size is over 32\n",
        "        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
        "            update_network()\n",
        "\n",
        "        if frame_count % update_target_network == 0:\n",
        "            model_target.load_state_dict(model.state_dict())\n",
        "\n",
        "        # Limit the state and reward history\n",
        "        if len(rewards_history) > max_memory_length:\n",
        "            del rewards_history[:1]\n",
        "            del state_history[:1]\n",
        "            del state_next_history[:1]\n",
        "            del action_history[:1]\n",
        "            del done_history[:1]\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    episode_count += 1\n",
        "    episode_reward_history.append(episode_reward)\n",
        "\n",
        "    # Update running reward to check condition for solving\n",
        "    if len(episode_reward_history) > 100:\n",
        "        del episode_reward_history[:1]\n",
        "    running_reward = np.mean(episode_reward_history)\n",
        "\n",
        "    if episode_count % 10 == 0:\n",
        "        print(f\"Episode: {episode_count}, Frame count: {frame_count}, Running reward: {running_reward}\")\n",
        "\n",
        "    if episode_count % 5000 == 0:\n",
        "        torch.save(model, 'model.{}'.format(episode_count))\n",
        "    if running_reward > 20:\n",
        "        print(f\"Solved at episode {episode_count}!\")\n",
        "        break\n",
        "    if episode_count >= 100:\n",
        "        break\n",
        "\n",
        "\n",
        "torch.save(model, 'model.final')"
      ],
      "metadata": {
        "id": "pgPMTl6F2_st",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c39246-8a67-47c2-b328-b6f0b8229289"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 10, Frame count: 7802, Running reward: 1.9\n",
            "Episode: 20, Frame count: 14858, Running reward: 1.6\n",
            "Episode: 30, Frame count: 21457, Running reward: 1.4\n",
            "Episode: 40, Frame count: 27962, Running reward: 1.275\n",
            "Episode: 50, Frame count: 33668, Running reward: 1.12\n",
            "Episode: 60, Frame count: 40203, Running reward: 1.1\n",
            "Episode: 70, Frame count: 45935, Running reward: 1.0142857142857142\n",
            "Episode: 80, Frame count: 53080, Running reward: 1.05\n",
            "Episode: 90, Frame count: 60210, Running reward: 1.0777777777777777\n",
            "Episode: 100, Frame count: 67215, Running reward: 1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, sys\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import imageio\n",
        "\n",
        "anim_file = 'atari.gif'\n",
        "\n",
        "turn =  0\n",
        "board, info = env.reset()\n",
        "state = preprocess_state(board)\n",
        "board, reward, done, _, info = env.step(1)\n",
        "state = preprocess_state(board)\n",
        "plt.imshow(board)\n",
        "plt.savefig('image_at_turn_{:04d}.png'.format(turn))\n",
        "\n",
        "for timestep in range(1, 100):\n",
        "    turn += 1\n",
        "    action = get_greedy_action(model, state.to('cuda'))\n",
        "    #print(action)\n",
        "    board, reward, done, _, info = env.step(action)\n",
        "    state = preprocess_state(board)\n",
        "    plt.imshow(board)\n",
        "    plt.savefig('image_at_turn_{:04d}.png'.format(turn))\n",
        "\n",
        "    if done:\n",
        "        break"
      ],
      "metadata": {
        "id": "s4lM71lH5FFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "1579d8b8-c3bf-4875-a2aa-84674b7492d1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate animated gif file\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "    filenames = glob.glob('image_at_turn_*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n"
      ],
      "metadata": {
        "id": "E4Wm0t1m5fa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4466a3-46e5-49b9-b6a6-d693ef20d23d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-512146e1f840>:6: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl2oc7BnD9Kl",
        "outputId": "ed5e5799-d437-4333-cfa9-f44d4cd97a38"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0D7apgpD7_h",
        "outputId": "e7864fb7-6d2c-4525-99fd-6b09d69be137"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/FLY_AI/RL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdSu8EfhEQtH",
        "outputId": "49ac7173-4fde-4560-c085-105f05ab6cfb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'P1. atari-breakout-cuda.ipynb'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp atari.gif drive/MyDrive/FLY_AI/RL/atari.gif #"
      ],
      "metadata": {
        "id": "LajeHU9JEk17"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8a1mKkFFEir"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}